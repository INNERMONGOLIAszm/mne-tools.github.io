{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n\nVisualize Raw data\n==================\n\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import os.path as op\n\nimport mne\n\ndata_path = op.join(mne.datasets.sample.data_path(), 'MEG', 'sample')\nraw = mne.io.read_raw_fif(op.join(data_path, 'sample_audvis_raw.fif'),\n                          add_eeg_ref=False)\nraw.set_eeg_reference()  # set EEG average reference\nevents = mne.read_events(op.join(data_path, 'sample_audvis_raw-eve.fif'))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The visualization module (:mod:`mne.viz`) contains all the plotting functions\nthat work in combination with MNE data structures. Usually the easiest way to\nuse them is to call a method of the data container. All of the plotting\nmethod names start with ``plot``. If you're using Ipython console, you can\njust write ``raw.plot`` and ask the interpreter for suggestions with a\n``tab`` key.\n\nTo visually inspect your raw data, you can use the python equivalent of\n``mne_browse_raw``.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "raw.plot(block=True)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The channels are color coded by channel type. Generally MEG channels are\ncolored in different shades of blue, whereas EEG channels are black. The\nscrollbar on right side of the browser window also tells us that two of the\nchannels are marked as ``bad``. Bad channels are color coded gray. By\nclicking the lines or channel names on the left, you can mark or unmark a bad\nchannel interactively. You can use +/- keys to adjust the scale (also = works\nfor magnifying the data). Note that the initial scaling factors can be set\nwith parameter ``scalings``. If you don't know the scaling factor for\nchannels, you can automatically set them by passing scalings='auto'. With\n``pageup/pagedown`` and ``home/end`` keys you can adjust the amount of data\nviewed at once. To see all the interactive features, hit ``?`` or click\n``help`` in the lower left corner of the browser window.\n\nThe channels are sorted by channel type by default. You can use the ``order``\nparameter of :func:`raw.plot <mne.io.Raw.plot>` to group the channels in a\ndifferent way. ``order='selection'`` uses the same channel groups as MNE-C's\nmne_browse_raw (see `CACCJEJD`). The selections are defined in\n``mne-python/mne/data/mne_analyze.sel`` and by modifying the channels there,\nyou can define your own selection groups. Notice that this also affects the\nselections returned by :func:`mne.read_selection`. By default the selections\nonly work for Neuromag data, but ``order='position'`` tries to mimic this\nbehavior for any data with sensor positions available. The channels are\ngrouped by sensor positions to 8 evenly sized regions. Notice that for this\nto work effectively, all the data channels in the channel array must be\npresent. The ``order`` parameter can also be passed as an array of ints\n(picks) to plot the channels in the given order.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "raw.plot(order='selection')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We read the events from a file and passed it as a parameter when calling the\nmethod. The events are plotted as vertical lines so you can see how they\nalign with the raw data.\n\nWe can check where the channels reside with ``plot_sensors``. Notice that\nthis method (along with many other MNE plotting functions) is callable using\nany MNE data container where the channel information is available.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "raw.plot_sensors(kind='3d', ch_type='mag', ch_groups='position')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We used ``ch_groups='position'`` to color code the different regions. It uses\nthe same algorithm for dividing the regions as ``order='position'`` of\n:func:`raw.plot <mne.io.Raw.plot>`. You can also pass a list of picks to\ncolor any channel group with different colors.\n\nNow let's add some ssp projectors to the raw data. Here we read them from a\nfile and plot them.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "projs = mne.read_proj(op.join(data_path, 'sample_audvis_eog-proj.fif'))\nraw.add_proj(projs)\nraw.plot_projs_topomap()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "The first three projectors that we see are the SSP vectors from empty room\nmeasurements to compensate for the noise. The fourth one is the average EEG\nreference. These are already applied to the data and can no longer be\nremoved. The next six are the EOG projections that we added. Every data\nchannel type has two projection vectors each. Let's try the raw browser\nagain.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "raw.plot()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Now click the `proj` button at the lower right corner of the browser\nwindow. A selection dialog should appear, where you can toggle the projectors\non and off. Notice that the first four are already applied to the data and\ntoggling them does not change the data. However the newly added projectors\nmodify the data to get rid of the EOG artifacts. Note that toggling the\nprojectors here doesn't actually modify the data. This is purely for visually\ninspecting the effect. See :func:`mne.io.Raw.del_proj` to actually remove the\nprojectors.\n\nRaw container also lets us easily plot the power spectra over the raw data.\nSee the API documentation for more info.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "raw.plot_psd()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Plotting channel-wise power spectra is just as easy. The layout is inferred\nfrom the data by default when plotting topo plots. This works for most data,\nbut it is also possible to define the layouts by hand. Here we select a\nlayout with only magnetometer channels and plot it. Then we plot the channel\nwise spectra of first 30 seconds of the data.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "layout = mne.channels.read_layout('Vectorview-mag')\nlayout.plot()\nraw.plot_psd_topo(tmax=30., fmin=5., fmax=60., n_fft=1024, layout=layout)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}