{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n================================================================\nMorphing source estimates: Moving data from one brain to another\n================================================================\n\nMorphing refers to the operation of transferring\n`source estimates <sphx_glr_auto_tutorials_plot_object_source_estimate.py>`\nfrom one anatomy to another. It is commonly referred as realignment in fMRI\nliterature. This operation is necessary for group studies as one needs\nthen data in a common space.\n\nIn this tutorial we will morph different kinds of source estimation results\nbetween individual subject spaces using :class:`mne.SourceMorph` object.\n\nWe will use precomputed data and morph surface and volume source estimates to a\nreference anatomy. The common space of choice will be FreeSurfer's 'fsaverage'\nSee `sphx_glr_auto_tutorials_plot_background_freesurfer.py` for more\ninformation. Method used for cortical surface data in based\non spherical registration [1]_ and Symmetric Diffeomorphic Registration (SDR)\nfor volumic data [2]_.\n\nFurthermore we will convert our volume source estimate into a NIfTI image using\n:meth:`morph.apply(..., output='nifti1') <mne.SourceMorph.apply>`.\n\nIn order to morph :class:`labels <mne.Label>` between subjects allowing the\ndefinition of labels in a one brain and transforming them to anatomically\nanalogous labels in another use :func:`mne.Label.morph`.\n\nWhy morphing?\n=============\n\nModern neuroimaging techniques, such as source reconstruction or fMRI analyses,\nmake use of advanced mathematical models and hardware to map brain activity\npatterns into a subject specific anatomical brain space.\n\nThis enables the study of spatio-temporal brain activity. The representation of\nspatio-temporal brain data is often mapped onto the anatomical brain structure\nto relate functional and anatomical maps. Thereby activity patterns are\noverlaid with anatomical locations that supposedly produced the activity.\nAnatomical MR images are often used as such or are transformed into an inflated\nsurface representations to serve as  \"canvas\" for the visualization.\n\nIn order to compute group level statistics, data representations across\nsubjects must be morphed to a common frame, such that anatomically and\nfunctional similar structures are represented at the same spatial location for\n*all subjects equally*.\n\nSince brains vary, morphing comes into play to tell us how the data\nproduced by subject A, would be represented on the brain of subject B.\n\nSee also this `tutorial on surface source estimation\n<sphx_glr_auto_tutorials_plot_mne_solutions.py>`\nor this `example on volumetric source estimation\n<sphx_glr_auto_examples_inverse_plot_compute_mne_inverse_volume.py>`.\n\nMorphing **volume** source estimates\n====================================\n\nA volumetric source estimate represents functional data in a volumetric 3D\nspace. The difference between a volumetric representation and a \"mesh\" (\ncommonly referred to as \"3D-model\"), is that the volume is \"filled\" while the\nmesh is \"empty\". Thus it is not only necessary to morph the points of the\nouter hull, but also the \"content\" of the volume.\n\nIn MNE-Python, volumetric source estimates are represented as\n:class:`mne.VolSourceEstimate`. The morph was successful if functional data of\nSubject A overlaps with anatomical data of Subject B, in the same way it does\nfor Subject A.\n\nSetting up :class:`mne.SourceMorph` for :class:`mne.VolSourceEstimate`\n----------------------------------------------------------------------\n\nMorphing volumetric data from subject A to subject B requires a non-linear\nregistration step between the anatomical T1 image of subject A to\nthe anatomical T1 image of subject B.\n\nMNE-Python uses the Symmetric Diffeomorphic Registration [2]_ as implemented\nin dipy_ [3]_ (See\n`tutorial <http://nipy.org/dipy/examples_built/syn_registration_3d.html>`_\nfrom dipy_ for more details).\n\n:class:`mne.SourceMorph` uses segmented anatomical MR images computed\nusing `FreeSurfer <sphx_glr_auto_tutorials_plot_background_freesurfer.py>`\nto compute the transformations. In order tell SourceMorph which MRIs to use,\n``subject_from`` and ``subject_to`` need to be defined as the name of the\nrespective folder in FreeSurfer's home directory.\n\nSee `sphx_glr_auto_examples_inverse_plot_morph_volume_stc.py`\nusage and for more details on:\n\n    - How to create a SourceMorph object for volumetric data\n\n    - Apply it to VolSourceEstimate\n\n    - Get the output is NIfTI format\n\n    - Save a SourceMorph object to disk\n\nMorphing **surface** source estimates\n=====================================\n\nA surface source estimate represents data relative to a 3-dimensional mesh of\nthe cortical surface computed using FreeSurfer. This mesh is defined by\nits vertices. If we want to morph our data from one brain to another, then\nthis translates to finding the correct transformation to transform each\nvertex from Subject A into a corresponding vertex of Subject B. Under the hood\n`FreeSurfer <sphx_glr_auto_tutorials_plot_background_freesurfer.py>`\nuses spherical representations to compute the morph, as relies on so\ncalled *morphing maps*.\n\nThe morphing maps\n-----------------\n\nThe MNE software accomplishes morphing with help of morphing\nmaps which can be either computed on demand or precomputed.\nThe morphing is performed with help\nof the registered spherical surfaces (``lh.sphere.reg`` and ``rh.sphere.reg`` )\nwhich must be produced in FreeSurfer.\nA morphing map is a linear mapping from cortical surface values\nin subject A ($x^{(A)}$) to those in another\nsubject B ($x^{(B)}$)\n\n\\begin{align}x^{(B)} = M^{(AB)} x^{(A)}\\ ,\\end{align}\n\nwhere $M^{(AB)}$ is a sparse matrix\nwith at most three nonzero elements on each row. These elements\nare determined as follows. First, using the aligned spherical surfaces,\nfor each vertex $x_j^{(B)}$, find the triangle $T_j^{(A)}$ on the\nspherical surface of subject A which contains the location $x_j^{(B)}$.\nNext, find the numbers of the vertices of this triangle and set\nthe corresponding elements on the *j* th row of $M^{(AB)}$ so that\n$x_j^{(B)}$ will be a linear interpolation between the triangle vertex\nvalues reflecting the location $x_j^{(B)}$ within the triangle\n$T_j^{(A)}$.\n\nIt follows from the above definition that in general\n\n\\begin{align}M^{(AB)} \\neq (M^{(BA)})^{-1}\\ ,\\end{align}\n\n*i.e.*,\n\n\\begin{align}x_{(A)} \\neq M^{(BA)} M^{(AB)} x^{(A)}\\ ,\\end{align}\n\neven if\n\n\\begin{align}x^{(A)} \\approx M^{(BA)} M^{(AB)} x^{(A)}\\ ,\\end{align}\n\n*i.e.*, the mapping is *almost* a bijection.\n\nMorphing maps can be computed on the fly or read with\n:func:`mne.read_morph_map`. Precomputed maps are\nlocated in ``$SUBJECTS_DIR/morph-maps``.\n\nThe names of the files in ``$SUBJECTS_DIR/morph-maps`` are\nof the form:\n\n <*A*> - <*B*> -``morph.fif`` ,\n\nwhere <*A*> and <*B*> are names of subjects. These files contain the maps\nfor both hemispheres, and in both directions, *i.e.*, both $M^{(AB)}$\nand $M^{(BA)}$, as defined above. Thus the files\n<*A*> - <*B*> -``morph.fif`` or <*B*> - <*A*> -``morph.fif`` are\nfunctionally equivalent. The name of the file produced depends on the role\nof <*A*> and <*B*> in the analysis.\n\nAbout smoothing\n---------------\n\nThe current estimates are normally defined only in a decimated\ngrid which is a sparse subset of the vertices in the triangular\ntessellation of the cortical surface. Therefore, any sparse set\nof values is distributed to neighboring vertices to make the visualized\nresults easily understandable. This procedure has been traditionally\ncalled smoothing but a more appropriate name\nmight be smudging or blurring in\naccordance with similar operations in image processing programs.\n\nIn MNE software terms, smoothing of the vertex data is an\niterative procedure, which produces a blurred image $x^{(N)}$ from\nthe original sparse image $x^{(0)}$ by applying\nin each iteration step a sparse blurring matrix:\n\n\\begin{align}x^{(p)} = S^{(p)} x^{(p - 1)}\\ .\\end{align}\n\nOn each row $j$ of the matrix $S^{(p)}$ there\nare $N_j^{(p - 1)}$ nonzero entries whose values\nequal $1/N_j^{(p - 1)}$. Here $N_j^{(p - 1)}$ is\nthe number of immediate neighbors of vertex $j$ which\nhad non-zero values at iteration step $p - 1$.\nMatrix $S^{(p)}$ thus assigns the average\nof the non-zero neighbors as the new value for vertex $j$.\nOne important feature of this procedure is that it tends to preserve\nthe amplitudes while blurring the surface image.\n\nOnce the indices non-zero vertices in $x^{(0)}$ and\nthe topology of the triangulation are fixed the matrices $S^{(p)}$ are\nfixed and independent of the data. Therefore, it would be in principle\npossible to construct a composite blurring matrix\n\n\\begin{align}S^{(N)} = \\prod_{p = 1}^N {S^{(p)}}\\ .\\end{align}\n\nHowever, it turns out to be computationally more effective\nto do blurring with an iteration. The above formula for $S^{(N)}$ also\nshows that the smudging (smoothing) operation is linear.\n\nFrom theory to practice\n-----------------------\n\nIn MNE-Python, surface source estimates are represented as\n:class:`mne.SourceEstimate` or :class:`mne.VectorSourceEstimate`. Those can\nbe used together with :class:`mne.SourceSpaces` or without.\n\nThe morph was successful if functional data of Subject A overlaps with\nanatomical surface data of Subject B, in the same way it does for Subject A.\n\nSee `sphx_glr_auto_examples_inverse_plot_morph_surface_stc.py`\nusage and for more details:\n\n    - How to create a :class:`mne.SourceMorph` object using\n      :func:`mne.compute_source_morph` for surface data\n\n    - Apply it to :class:`mne.SourceEstimate` or\n      :class:`mne.VectorSourceEstimate`\n\n    - Save a :class:`mne.SourceMorph` object to disk\n\nPlease see also Gramfort *et al.* (2013) [4]_.\n\nReferences\n==========\n.. [1] Greve D. N., Van der Haegen L., Cai Q., Stufflebeam S., Sabuncu M.\n       R., Fischl B., Brysbaert M.\n       A Surface-based Analysis of Language Lateralization and Cortical\n       Asymmetry. Journal of Cognitive Neuroscience 25(9), 1477-1492, 2013.\n.. [2] Avants, B. B., Epstein, C. L., Grossman, M., & Gee, J. C. (2009).\n       Symmetric Diffeomorphic Image Registration with Cross- Correlation:\n       Evaluating Automated Labeling of Elderly and Neurodegenerative\n       Brain, 12(1), 26-41.\n.. [3] Garyfallidis E, Brett M, Amirbekian B, Rokem A, van der Walt S,\n       Descoteaux M, Nimmo-Smith I and Dipy Contributors (2014). DIPY, a\n       library for the analysis of diffusion MRI data. Frontiers in\n       Neuroinformatics, vol.8, no.8.\n.. [4] Gramfort A., Luessi M., Larson E., Engemann D. A., Strohmeier D.,\n       Brodbeck C., Goj R., Jas. M., Brooks T., Parkkonen L. & H\u00e4m\u00e4l\u00e4inen, M.\n       (2013). MEG and EEG data analysis with MNE-Python. Frontiers in\n       neuroscience, 7, 267.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}