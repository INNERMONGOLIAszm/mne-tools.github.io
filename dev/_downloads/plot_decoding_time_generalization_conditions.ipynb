{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Decoding sensor space data with generalization across time and conditions\n\n\nThis example runs the analysis computed in:\n\nJean-Remi King, Alexandre Gramfort, Aaron Schurger, Lionel Naccache\nand Stanislas Dehaene, \"Two distinct dynamic modes subtend the detection of\nunexpected sounds\", PLOS ONE, 2013,\nhttp://www.ncbi.nlm.nih.gov/pubmed/24475052\n\nKing & Dehaene (2014) 'Characterizing the dynamics of mental\nrepresentations: the temporal generalization method', Trends In Cognitive\nSciences, 18(4), 203-210.\nhttp://www.ncbi.nlm.nih.gov/pubmed/24593982\n\nThe idea is to learn at one time instant and assess if the decoder\ncan predict accurately over time and on a second set of conditions.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "# Authors: Jean-Remi King <jeanremi.king@gmail.com>\n#          Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n#          Denis Engemann <denis.engemann@gmail.com>\n#\n# License: BSD (3-clause)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport mne\nfrom mne.datasets import sample\nfrom mne.decoding.search_light import GeneralizationLight\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\n\nprint(__doc__)\n\n# Preprocess data\ndata_path = sample.data_path()\n# Load and filter data, set up epochs\nraw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'\nevents_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw-eve.fif'\nraw = mne.io.read_raw_fif(raw_fname, preload=True)\npicks = mne.pick_types(raw.info, meg='mag')  # Pick magnetometers only\nevents = mne.read_events(events_fname)\nevent_id = {'AudL': 1, 'AudR': 2, 'VisL': 3, 'VisR': 4}\ndecim = 2  # decimate to make the example faster to run\nepochs = mne.Epochs(raw, events, event_id, -0.050, 0.400, proj=True,\n                    picks=picks, baseline=None, preload=True,\n                    decim=decim, verbose=False)\n\n# We will train the classifier on all left visual vs auditory trials\n# and test on all right visual vs auditory trials.\n\n# In this case, because the test data is independent from the train data,\n# we do not need a cross validation.\n\n# Define events of interest\ntriggers = epochs.events[:, 2]\n\n\n# Each estimator fitted at each time point is an independent Scikit-Learn\n# pipeline with a ``fit``, and a ``score`` method.\ngat = GeneralizationLight(\n    make_pipeline(StandardScaler(), LogisticRegression()),\n    n_jobs=1)\n\n# Fit: for our left events, which ones are visual?\nX = epochs[('AudL', 'VisL')].get_data()\ny = triggers[np.in1d(triggers, (1, 3))] == 3\ngat.fit(X, y)\n\n# Generalize: for our right events, which ones are visual?\nX = epochs[('AudR', 'VisR')].get_data()\ny = triggers[np.in1d(triggers, (2, 4))] == 4\nscore = gat.score(X, y)\n\n# Plot temporal generalization accuracies.\nextent = epochs.times[[0, -1, 0, -1]]\nfig, ax = plt.subplots(1)\nim = ax.matshow(score, origin='lower', cmap='RdBu_r', vmin=0., vmax=1.,\n                extent=extent)\nticks = np.arange(0., .401, .100)\nax.set_xticks(ticks)\nax.set_xticklabels(ticks)\nax.set_yticks(ticks)\nax.set_yticklabels(ticks)\nax.axvline(0, color='k')\nax.axhline(0, color='k')\nplt.colorbar(im)\nplt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}