{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compute LCMV inverse solution on evoked data in volume source space\n\n\nCompute LCMV inverse solution on an auditory evoked dataset in a volume source\nspace. It stores the solution in a nifti file for visualisation, e.g. with\nFreeview.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n#\n# License: BSD (3-clause)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport mne\nfrom mne.datasets import sample\nfrom mne.beamformer import make_lcmv, apply_lcmv\n\nfrom nilearn.plotting import plot_stat_map\nfrom nilearn.image import index_img\n\nprint(__doc__)\n\n# sphinx_gallery_thumbnail_number = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data preprocessing:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = sample.data_path()\nraw_fname = data_path + '/MEG/sample/sample_audvis_raw.fif'\nevent_fname = data_path + '/MEG/sample/sample_audvis_raw-eve.fif'\nfname_fwd = data_path + '/MEG/sample/sample_audvis-meg-vol-7-fwd.fif'\n\n# Get epochs\nevent_id, tmin, tmax = [1, 2], -0.2, 0.5\n\n# Setup for reading the raw data\nraw = mne.io.read_raw_fif(raw_fname, preload=True)\nraw.info['bads'] = ['MEG 2443', 'EEG 053']  # 2 bads channels\nevents = mne.read_events(event_fname)\n\n# Set up pick list: gradiometers and magnetometers, excluding bad channels\npicks = mne.pick_types(raw.info, meg=True, eeg=False, stim=True, eog=True,\n                       exclude='bads')\n\n# Pick the channels of interest\nraw.pick_channels([raw.ch_names[pick] for pick in picks])\n\n# Re-normalize our empty-room projectors, so they are fine after subselection\nraw.info.normalize_proj()\n\n# Read epochs\nproj = False  # already applied\nepochs = mne.Epochs(raw, events, event_id, tmin, tmax,\n                    baseline=(None, 0), preload=True, proj=proj,\n                    reject=dict(grad=4000e-13, mag=4e-12, eog=150e-6))\nevoked = epochs.average()\n\n# Visualize sensor space data\nevoked.plot_joint(ts_args=dict(time_unit='s'),\n                  topomap_args=dict(time_unit='s'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute covariance matrices, fit and apply  spatial filter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Read regularized noise covariance and compute regularized data covariance\nnoise_cov = mne.compute_covariance(epochs, tmin=tmin, tmax=0, method='shrunk')\ndata_cov = mne.compute_covariance(epochs, tmin=0.04, tmax=0.15,\n                                  method='shrunk')\n\n# Read forward model\nforward = mne.read_forward_solution(fname_fwd)\n\n# Compute weights of free orientation (vector) beamformer with weight\n# normalization (neural activity index, NAI). Providing a noise covariance\n# matrix enables whitening of the data and forward solution. Source orientation\n# is optimized by setting pick_ori to 'max-power'.\n# weight_norm can also be set to 'unit-noise-gain'. Source orientation can also\n# be 'normal' (but only when using a surface-based source space) or None,\n# which computes a vector beamfomer. Note, however, that not all combinations\n# of orientation selection and weight normalization are implemented yet.\nfilters = make_lcmv(evoked.info, forward, data_cov, reg=0.05,\n                    noise_cov=noise_cov, pick_ori='max-power',\n                    weight_norm='nai')\n\n# Apply this spatial filter to the evoked data.\nstc = apply_lcmv(evoked, filters, max_ori_out='signed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot source space activity:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# take absolute values for plotting\nstc.data[:, :] = np.abs(stc.data)\n\n# Save result in stc files\nstc.save('lcmv-vol')\n\nstc.crop(0.0, 0.2)\n\n# Save result in a 4D nifti file\nimg = stc.as_volume(forward['src'], mri_resolution=False)\n\nt1_fname = data_path + '/subjects/sample/mri/T1.mgz'\n\n# Plotting with nilearn ######################################################\n# Based on the visualization of the sensor space data (gradiometers), plot\n# activity at 88 ms\nidx = stc.time_as_index(0.088)\nplot_stat_map(index_img(img, idx), t1_fname, threshold=0.45,\n              title='LCMV (t=%.3f s.)' % stc.times[idx])\n\n# plot source time courses with the maximum peak amplitudes at 88 ms\nplt.figure()\nplt.plot(stc.times, stc.data[np.argsort(np.max(stc.data[:, idx],\n                                               axis=1))[-40:]].T)\nplt.xlabel('Time (ms)')\nplt.ylabel('LCMV value')\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}