.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_inverse_plot_rap_music.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_inverse_plot_rap_music.py:


================================
Compute Rap-Music on evoked data
================================

Compute a Recursively Applied and Projected MUltiple Signal Classification
(RAP-MUSIC) [1]_ on evoked data.

References
----------
.. [1] J.C. Mosher and R.M. Leahy. 1999. Source localization using recursively
       applied and projected (RAP) MUSIC. Trans. Sig. Proc. 47, 2
       (February 1999), 332-340.
       DOI=10.1109/78.740118 https://doi.org/10.1109/78.740118




.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_001.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_002.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_003.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_examples/inverse/images/sphx_glr_plot_rap_music_004.png
            :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Reading /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        Found the data of interest:
            t =    -199.80 ...     499.49 ms (Right Auditory)
            0 CTF compensation matrices available
            nave = 61 - aspect type = 100
    Projections have already been applied. Setting proj attribute to True.
    Applying baseline correction (mode: mean)
    Reading forward solution from /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif...
        Reading a source space...
        Computing patch statistics...
        Patch information added...
        Distance information added...
        [done]
        Reading a source space...
        Computing patch statistics...
        Patch information added...
        Distance information added...
        [done]
        2 source spaces read
        Desired named matrix (kind = 3523) not available
        Read MEG forward solution (7498 sources, 306 channels, free orientations)
        Desired named matrix (kind = 3523) not available
        Read EEG forward solution (7498 sources, 60 channels, free orientations)
        MEG and EEG forward solutions combined
        Source spaces transformed to the forward solution coordinate frame
        366 x 366 full covariance (kind = 1) found.
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        305 out of 366 channels remain after picking
        Created an SSP operator (subspace dimension = 3)
    estimated rank (mag + grad): 302
    Setting small MEG eigenvalues to zero.
    Not doing PCA for MEG.
    Total rank is 302
    source 1 found: p = 1834
    ori = -0.24703241422079103 0.7764326014737665 0.5797649538329536
    source 2 found: p = 5304
    ori = -0.5154591813876829 0.5345116895494453 0.6697753997110802
    4 projection items deactivated
    Created an SSP operator (subspace dimension = 3)
    4 projection items activated
    SSP projectors applied...




|


.. code-block:: python


    # Author: Yousra Bekhti <yousra.bekhti@gmail.com>
    #
    # License: BSD (3-clause)

    import mne

    from mne.datasets import sample
    from mne.beamformer import rap_music
    from mne.viz import plot_dipole_locations, plot_dipole_amplitudes

    print(__doc__)

    data_path = sample.data_path()
    subjects_dir = data_path + '/subjects'
    fwd_fname = data_path + '/MEG/sample/sample_audvis-meg-eeg-oct-6-fwd.fif'
    evoked_fname = data_path + '/MEG/sample/sample_audvis-ave.fif'
    cov_fname = data_path + '/MEG/sample/sample_audvis-cov.fif'

    # Read the evoked response and crop it
    condition = 'Right Auditory'
    evoked = mne.read_evokeds(evoked_fname, condition=condition,
                              baseline=(None, 0))
    evoked.crop(tmin=0.05, tmax=0.15)  # select N100

    evoked.pick_types(meg=True, eeg=False)

    # Read the forward solution
    forward = mne.read_forward_solution(fwd_fname)

    # Read noise covariance matrix
    noise_cov = mne.read_cov(cov_fname)

    dipoles, residual = rap_music(evoked, forward, noise_cov, n_dipoles=2,
                                  return_residual=True, verbose=True)
    trans = forward['mri_head_t']
    plot_dipole_locations(dipoles, trans, 'sample', subjects_dir=subjects_dir)
    plot_dipole_amplitudes(dipoles)

    # Plot the evoked data and the residual.
    evoked.plot(ylim=dict(grad=[-300, 300], mag=[-800, 800], eeg=[-6, 8]),
                time_unit='s')
    residual.plot(ylim=dict(grad=[-300, 300], mag=[-800, 800], eeg=[-6, 8]),
                  time_unit='s')

**Total running time of the script:** ( 0 minutes  23.464 seconds)


.. _sphx_glr_download_auto_examples_inverse_plot_rap_music.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_rap_music.py <plot_rap_music.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_rap_music.ipynb <plot_rap_music.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
