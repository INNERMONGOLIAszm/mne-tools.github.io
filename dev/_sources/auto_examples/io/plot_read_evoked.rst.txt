.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_examples_io_plot_read_evoked.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_io_plot_read_evoked.py:


==================================
Reading and writing an evoked file
==================================

This script shows how to read and write evoked datasets.



.. code-block:: python

    # Author: Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>
    #
    # License: BSD (3-clause)

    from mne import read_evokeds
    from mne.datasets import sample

    print(__doc__)

    data_path = sample.data_path()

    fname = data_path + '/MEG/sample/sample_audvis-ave.fif'

    # Reading
    condition = 'Left Auditory'
    evoked = read_evokeds(fname, condition=condition, baseline=(None, 0),
                          proj=True)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Reading /home/circleci/mne_data/MNE-sample-data/MEG/sample/sample_audvis-ave.fif ...
        Read a total of 4 projection items:
            PCA-v1 (1 x 102) active
            PCA-v2 (1 x 102) active
            PCA-v3 (1 x 102) active
            Average EEG reference (1 x 60) active
        Found the data of interest:
            t =    -199.80 ...     499.49 ms (Left Auditory)
            0 CTF compensation matrices available
            nave = 55 - aspect type = 100
    Projections have already been applied. Setting proj attribute to True.
    Applying baseline correction (mode: mean)


Show result as a butterfly plot:
By using exclude=[] bad channels are not excluded and are shown in red



.. code-block:: python

    evoked.plot(exclude=[], time_unit='s')

    # Show result as a 2D image (x: time, y: channels, color: amplitude)
    evoked.plot_image(exclude=[], time_unit='s')




.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_examples/io/images/sphx_glr_plot_read_evoked_001.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_examples/io/images/sphx_glr_plot_read_evoked_002.png
            :class: sphx-glr-multi-img




Use :func:`mne.Evoked.save` or :func:`mne.write_evokeds` to write the evoked
responses to a file.


**Total running time of the script:** ( 0 minutes  1.959 seconds)


.. _sphx_glr_download_auto_examples_io_plot_read_evoked.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_read_evoked.py <plot_read_evoked.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_read_evoked.ipynb <plot_read_evoked.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
