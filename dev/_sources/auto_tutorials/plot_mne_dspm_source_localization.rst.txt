.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_auto_tutorials_plot_mne_dspm_source_localization.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_plot_mne_dspm_source_localization.py:


Source localization with MNE/dSPM/sLORETA/eLORETA
=================================================

The aim of this tutorial is to teach you how to compute and apply a linear
inverse method such as MNE/dSPM/sLORETA/eLORETA on evoked/raw/epochs data.



.. code-block:: python

    import numpy as np
    import matplotlib.pyplot as plt

    import mne
    from mne.datasets import sample
    from mne.minimum_norm import make_inverse_operator, apply_inverse

    # sphinx_gallery_thumbnail_number = 9







Process MEG data



.. code-block:: python


    data_path = sample.data_path()
    raw_fname = data_path + '/MEG/sample/sample_audvis_filt-0-40_raw.fif'

    raw = mne.io.read_raw_fif(raw_fname)  # already has an average reference
    events = mne.find_events(raw, stim_channel='STI 014')

    event_id = dict(aud_r=1)  # event trigger and conditions
    tmin = -0.2  # start of each epoch (200ms before the trigger)
    tmax = 0.5  # end of each epoch (500ms after the trigger)
    raw.info['bads'] = ['MEG 2443', 'EEG 053']
    picks = mne.pick_types(raw.info, meg=True, eeg=False, eog=True,
                           exclude='bads')
    baseline = (None, 0)  # means from the first instant to t = 0
    reject = dict(grad=4000e-13, mag=4e-12, eog=150e-6)

    epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,
                        baseline=baseline, reject=reject)







Compute regularized noise covariance
------------------------------------

For more details see :ref:`tut_compute_covariance`.



.. code-block:: python


    noise_cov = mne.compute_covariance(
        epochs, tmax=0., method=['shrunk', 'empirical'], verbose=True)

    fig_cov, fig_spectra = mne.viz.plot_cov(noise_cov, raw.info)




.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_001.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_002.png
            :class: sphx-glr-multi-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Loading data for 72 events and 106 original time points ...
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on MAG : ['MEG 1711']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
        Rejecting  epoch based on EOG : ['EOG 061']
    17 bad epochs dropped
    Estimating covariance using SHRUNK
    Done.
    Estimating covariance using EMPIRICAL
    Done.
    Using cross-validation to select the best estimator.
    Number of samples used : 1705
    log-likelihood on unseen data (descending order):
       shrunk: -1480.993
       empirical: -1628.225
    selecting best estimator: shrunk
    [done]


Compute the evoked response
---------------------------
Let's just use MEG channels for simplicity.



.. code-block:: python


    evoked = epochs.average().pick_types(meg=True)
    evoked.plot(time_unit='s')
    evoked.plot_topomap(times=np.linspace(0.05, 0.15, 5), ch_type='mag',
                        time_unit='s')

    # Show whitening
    evoked.plot_white(noise_cov, time_unit='s')

    del epochs  # to save memory




.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_003.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_004.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_005.png
            :class: sphx-glr-multi-img




Inverse modeling: MNE/dSPM on evoked and raw data
-------------------------------------------------



.. code-block:: python


    # Read the forward solution and compute the inverse operator
    fname_fwd = data_path + '/MEG/sample/sample_audvis-meg-oct-6-fwd.fif'
    fwd = mne.read_forward_solution(fname_fwd)

    # make an MEG inverse operator
    info = evoked.info
    inverse_operator = make_inverse_operator(info, fwd, noise_cov,
                                             loose=0.2, depth=0.8)
    del fwd

    # You can write it to disk with::
    #
    #     >>> from mne.minimum_norm import write_inverse_operator
    #     >>> write_inverse_operator('sample_audvis-meg-oct-6-inv.fif',
    #                                inverse_operator)







Compute inverse solution
------------------------



.. code-block:: python


    method = "dSPM"
    snr = 3.
    lambda2 = 1. / snr ** 2
    stc = apply_inverse(evoked, inverse_operator, lambda2,
                        method=method, pick_ori=None)







Visualization
-------------
View activation time-series



.. code-block:: python


    plt.figure()
    plt.plot(1e3 * stc.times, stc.data[::100, :].T)
    plt.xlabel('time (ms)')
    plt.ylabel('%s value' % method)
    plt.show()




.. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_006.png
    :class: sphx-glr-single-img




Here we use peak getter to move visualization to the time point of the peak
and draw a marker at the maximum peak vertex.



.. code-block:: python


    vertno_max, time_max = stc.get_peak(hemi='rh')

    subjects_dir = data_path + '/subjects'
    surfer_kwargs = dict(
        hemi='rh', subjects_dir=subjects_dir,
        clim=dict(kind='value', lims=[8, 12, 15]), views='lateral',
        initial_time=time_max, time_unit='s', size=(800, 800), smoothing_steps=5)
    brain = stc.plot(**surfer_kwargs)
    brain.add_foci(vertno_max, coords_as_verts=True, hemi='rh', color='blue',
                   scale_factor=0.6, alpha=0.5)
    brain.add_text(0.1, 0.9, 'dSPM (plus location of maximal activation)', 'title',
                   font_size=14)




.. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_007.png
    :class: sphx-glr-single-img




Morph data to average brain
---------------------------



.. code-block:: python


    fs_vertices = [np.arange(10242)] * 2  # fsaverage is special this way
    morph_mat = mne.compute_morph_matrix(
        'sample', 'fsaverage', stc.vertices, fs_vertices, smooth=None,
        subjects_dir=subjects_dir)
    stc_fsaverage = stc.morph_precomputed('fsaverage', fs_vertices, morph_mat)
    brain = stc_fsaverage.plot(**surfer_kwargs)
    brain.add_text(0.1, 0.9, 'Morphed to fsaverage', 'title', font_size=20)
    del stc_fsaverage




.. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_008.png
    :class: sphx-glr-single-img




Dipole orientations
-------------------
The ``pick_ori`` parameter of the
:func:`mne.minimum_norm.apply_inverse` function controls
the orientation of the dipoles. One useful setting is ``pick_ori='vector'``,
which will return an estimate that does not only contain the source power at
each dipole, but also the orientation of the dipoles.



.. code-block:: python


    stc_vec = apply_inverse(evoked, inverse_operator, lambda2,
                            method=method, pick_ori='vector')
    brain = stc_vec.plot(**surfer_kwargs)
    brain.add_text(0.1, 0.9, 'Vector solution', 'title', font_size=20)
    del stc_vec




.. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_009.png
    :class: sphx-glr-single-img




Note that there is a relationship between the orientation of the dipoles and
the surface of the cortex. For this reason, we do not use an inflated
cortical surface for visualization, but the original surface used to define
the source space.

For more information about dipole orientations, see
:ref:`sphx_glr_auto_tutorials_plot_dipole_orientations.py`.


Now let's look at each solver:



.. code-block:: python


    for mi, (method, lims) in enumerate((('dSPM', [8, 12, 15]),
                                         ('sLORETA', [3, 5, 7]),
                                         ('eLORETA', [0.75, 1.25, 1.75]),)):
        surfer_kwargs['clim']['lims'] = lims
        stc = apply_inverse(evoked, inverse_operator, lambda2,
                            method=method, pick_ori=None)
        brain = stc.plot(figure=mi, **surfer_kwargs)
        brain.add_text(0.1, 0.9, method, 'title', font_size=20)
        del stc



.. rst-class:: sphx-glr-horizontal


    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_010.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_011.png
            :class: sphx-glr-multi-img

    *

      .. image:: /auto_tutorials/images/sphx_glr_plot_mne_dspm_source_localization_012.png
            :class: sphx-glr-multi-img




**Total running time of the script:** ( 3 minutes  4.898 seconds)


.. _sphx_glr_download_auto_tutorials_plot_mne_dspm_source_localization.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_mne_dspm_source_localization.py <plot_mne_dspm_source_localization.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_mne_dspm_source_localization.ipynb <plot_mne_dspm_source_localization.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
